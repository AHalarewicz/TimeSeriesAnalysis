{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import LSTR\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.linear_model import SGDRegressor as SGD\n",
    "import joblib\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters and Model Architecture\n",
    "N_LAYERS = 10\n",
    "N_NODES = 25\n",
    "TEST_SIZE = 0.25\n",
    "DAYS_TO_CLIP = 1\n",
    "EPOCHS = 2\n",
    "\n",
    "#tf.random.set_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back_5</th>\n",
       "      <th>back_4</th>\n",
       "      <th>back_3</th>\n",
       "      <th>back_2</th>\n",
       "      <th>back_1</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>-0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>-0.009852</td>\n",
       "      <td>-0.020001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>-0.009852</td>\n",
       "      <td>-0.020001</td>\n",
       "      <td>0.002522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>-0.009852</td>\n",
       "      <td>-0.020001</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>-0.028022</td>\n",
       "      <td>0.105866</td>\n",
       "      <td>0.189679</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>-0.108411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>0.105866</td>\n",
       "      <td>0.189679</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>-0.108411</td>\n",
       "      <td>-0.061875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>0.189679</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>-0.108411</td>\n",
       "      <td>-0.061875</td>\n",
       "      <td>-0.020835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.128803</td>\n",
       "      <td>-0.108411</td>\n",
       "      <td>-0.061875</td>\n",
       "      <td>-0.020835</td>\n",
       "      <td>-0.131981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>0.128803</td>\n",
       "      <td>-0.108411</td>\n",
       "      <td>-0.061875</td>\n",
       "      <td>-0.020835</td>\n",
       "      <td>-0.131981</td>\n",
       "      <td>-0.058528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14663 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              back_5    back_4    back_3    back_2    back_1  Adj Close\n",
       "Date                                                                   \n",
       "1962-01-02       NaN       NaN       NaN       NaN       NaN   0.019803\n",
       "1962-01-03       NaN       NaN       NaN       NaN  0.019803  -0.009852\n",
       "1962-01-04       NaN       NaN       NaN  0.019803 -0.009852  -0.020001\n",
       "1962-01-05       NaN       NaN  0.019803 -0.009852 -0.020001   0.002522\n",
       "1962-01-08       NaN  0.019803 -0.009852 -0.020001  0.002522   0.002516\n",
       "...              ...       ...       ...       ...       ...        ...\n",
       "2020-03-26 -0.028022  0.105866  0.189679  0.217677  0.128803  -0.108411\n",
       "2020-03-27  0.105866  0.189679  0.217677  0.128803 -0.108411  -0.061875\n",
       "2020-03-30  0.189679  0.217677  0.128803 -0.108411 -0.061875  -0.020835\n",
       "2020-03-31  0.217677  0.128803 -0.108411 -0.061875 -0.020835  -0.131981\n",
       "2020-04-01  0.128803 -0.108411 -0.061875 -0.020835 -0.131981  -0.058528\n",
       "\n",
       "[14663 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify location of time series data\n",
    "file_path = '../data/interim/time_series.csv'\n",
    "\n",
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    Read csv data from the specified file location.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file, index_col='Date')\n",
    "    return df\n",
    "\n",
    "\n",
    "# read time series data\n",
    "time_series_df = read_data(file_path)\n",
    "\n",
    "# test_df will be used to test on recent market performance\n",
    "test_df = read_data(file_path) \n",
    "\n",
    "\n",
    "def clip_recent_days(df, n_days):\n",
    "    \"\"\"\n",
    "    remove recent days from data frame\n",
    "    \"\"\"\n",
    "    return(df[:-n_days])\n",
    "\n",
    "\n",
    "# clip most recent days\n",
    "time_series_df = clip_recent_days(time_series_df, DAYS_TO_CLIP)\n",
    "\n",
    "# inspect the time series dataframe\n",
    "time_series_df\n",
    "\n",
    "#time_series_df = pd.read_csv('../data/interim/time_series.csv', index_col='Date')\n",
    "#test_df = time_series_df.copy()\n",
    "#time_series_df = time_series_df[:-DAYS_TO_CLIP]\n",
    "#time_series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14663 entries, 1962-01-02 to 2020-04-01\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   back_5     14658 non-null  float64\n",
      " 1   back_4     14659 non-null  float64\n",
      " 2   back_3     14660 non-null  float64\n",
      " 3   back_2     14661 non-null  float64\n",
      " 4   back_1     14662 non-null  float64\n",
      " 5   Adj Close  14663 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 801.9+ KB\n"
     ]
    }
   ],
   "source": [
    "time_series_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              back_5    back_4    back_3    back_2    back_1\n",
       " Date                                                        \n",
       " 2020-04-01  0.128803 -0.108411 -0.061875 -0.020835 -0.131981,\n",
       " Date\n",
       " 2020-04-01   -0.058528\n",
       " Name: Adj Close, dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tomorrow(df):\n",
    "    tomorrow = df.tail(1)\n",
    "    predictors = tomorrow.iloc[:,:5]\n",
    "    target = tomorrow.iloc[:,-1]\n",
    "    return predictors, target\n",
    "    \n",
    "tomorrows_predictors, tomorrows_target = get_tomorrow(time_series_df)\n",
    "\n",
    "get_tomorrow(time_series_df)\n",
    "    \n",
    "#tomorrow = time_series_df.tail(1)\n",
    "#tomorrows_predictors = tomorrow.iloc[:,:5]\n",
    "#tomorrows_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predictors_and_targets(df):\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    predictors = df[['back_5', 'back_4', 'back_3', 'back_2', 'back_1']].values\n",
    "    assert type(predictors) is np.ndarray\n",
    "    \n",
    "    n_cols = predictors.shape[1]\n",
    "    \n",
    "    targets = df[['Adj Close']].values\n",
    "    assert type(targets) is np.ndarray\n",
    "    \n",
    "    return predictors, targets, n_cols\n",
    "\n",
    "\n",
    "#time_series_df = time_series_df.dropna()\n",
    "#time_series_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of predictors\n",
    "#predictors = time_series_df[['back_5', 'back_4', 'back_3', 'back_2', 'back_1']].values\n",
    "#n_cols = predictors.shape[1]\n",
    "#type(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of targets\n",
    "#target = time_series_df[['Adj Close']].values\n",
    "#type(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, targets, n_cols = format_predictors_and_targets(time_series_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                150       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 6,026\n",
      "Trainable params: 6,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_sequential(n_nodes, n_layers, n_cols):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_nodes, activation='relu', input_shape=(n_cols,)))\n",
    "    \n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(n_nodes, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_sequential(N_NODES, N_LAYERS, n_cols)\n",
    "model.summary()\n",
    "        \n",
    "    \n",
    "\n",
    "#initialize a sequential keras model\n",
    "#model = Sequential()\n",
    "\n",
    "# build with N_LAYERS N_NODES each\n",
    "#model.add(Dense(N_NODES, activation='relu', input_shape=(n_cols,)))\n",
    "#for i in range(N_LAYERS-1):\n",
    "#    model.add(Dense(N_NODES, activation='relu'))\n",
    "\n",
    "\n",
    "# build final layer that will contain the output prediction\n",
    "#model.add(Dense(1))\n",
    "\n",
    "# compile the model with ADAM\n",
    "# will adjust the learning rate as it does gradient descent\n",
    "# MSE loss function is best for regression problems\n",
    "#model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# verify model structure\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10993/10993 [==============================] - 1s 117us/step - loss: 4.2538e-04\n",
      "Epoch 2/2\n",
      "10993/10993 [==============================] - 1s 81us/step - loss: 4.2506e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7b7287af4490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # fit the model\n",
    "# apply back propagation and gradient descent\n",
    "model.fit(X_train, y_train, use_multiprocessing=True, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                150       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 6,026\n",
      "Trainable params: 6,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# save and load model\n",
    "model.save('../models/keras.h5')\n",
    "model = load_model('../models/keras.h5')\n",
    "\n",
    "# verify model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "output = predictions\n",
    "output = pd.DataFrame(output)\n",
    "output.to_csv('../data/interim/keras_dense_predictions.csv')\n",
    "def revert_exp(predictions, y_test):\n",
    "    predictions = np.exp(predictions)\n",
    "    y_test_exp = np.exp(y_test)\n",
    "    return predictions, y_test_exp\n",
    "\n",
    "# min(y_test_exp), max(y_test_exp)\n",
    "predictions, y_test_exp = revert_exp(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [53.964194, 45.865303, 53.878943, 53.793691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting change in stock price with 53.233288% accuracy\n"
     ]
    }
   ],
   "source": [
    "#### this is very good\n",
    "\n",
    "def get_accuracy(y, pred):\n",
    "    \n",
    "    #scale and shift binary results\n",
    "    # -1 -> stock went down\n",
    "    # +1 -> stock increased or stayed the same\n",
    "    y = ((y>=1)*2)-1\n",
    "    pred = ((pred>=1)*2)-1\n",
    "    \n",
    "    # stocks move in the same direction when a_i*b_i is positive\n",
    "    accuracy = (np.sum((y*pred)>=0)/len(y))*100\n",
    "    \n",
    "    print(\"Predicting change in stock price with %f%s accuracy\" % (accuracy,'%'))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "scores.append(get_accuracy(y_test_exp, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Stop here'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b84a2b4da15e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stop here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Stop here'"
     ]
    }
   ],
   "source": [
    "int('Stop here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading dates where COVID-19 affected stock market need to be excluded. if included, accuracy drops to ~48%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we can make and evaluate predictions, It's time for some Cross-Validation to improve the Neural Network's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_CLIPPED = [1, 5, 10, 15, 20, 25, 30, 35, 40]\n",
    "TEST_SIZES = [0.15, 0.20, 0.25, 0.35, 0.40]\n",
    "NODES = [5, 25, 50, 75, 100, 150, 200, 500]\n",
    "LAYERS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "EPOCHS = [1, 2, 3, 4, 5, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DAYS_CLIPPED) * len(TEST_SIZES) * len(NODES) * len(layers) * len(epochs)\n",
    "\n",
    "#21,600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_cross_validation():\n",
    "    #best_layers = 0\n",
    "    #best_nodes = 0\n",
    "    #best_test_size = 0\n",
    "    #best_days_clipped = 0\n",
    "    #best_epochs = 0\n",
    "    best_mean_accuracy = 0\n",
    "    loop = 0\n",
    "    \n",
    "    # read_data\n",
    "    time_series_df = read_data(file_path)\n",
    "    \n",
    "    \n",
    "    for DAYS_TO_CLIP in DAYS_CLIPPED:\n",
    "        \n",
    "        time_series_df = clip_recent_days(time_series_df, DAYS_TO_CLIP)\n",
    "        predictors, targets, n_cols = format_predictors_and_targets(time_series_df)\n",
    "        \n",
    "        \n",
    "        for TEST_SIZE in TEST_SIZES:\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=TEST_SIZE)\n",
    "            \n",
    "            \n",
    "            for N_NODES in NODES:\n",
    "                for N_LAYERS in LAYERS:\n",
    "                    \n",
    "                    model = build_sequential(N_NODES, N_LAYERS, n_cols)\n",
    "                    \n",
    "                    \n",
    "                    for N_EPOCHS in EPOCHS:\n",
    "                        \n",
    "                        accuracies = []\n",
    "                        \n",
    "                        for i in range(10):\n",
    "                            \n",
    "                            model.fit(X_train, y_train, use_multiprocessing=True, epochs=N_EPOCHS)\n",
    "                            predictions = model.predict(X_test)\n",
    "                            predictions, y_test_exp = revert_exp(predictions, y_test)\n",
    "                            accuracies.append(get_accuracy(y_test_exp, predictions))\n",
    "                            loop += 1\n",
    "                            print('PROGRESS: ', loop)\n",
    "                        \n",
    "                        mean_accuracy = np.mean(accuracies)\n",
    "                        \n",
    "                        if mean_accuracy>best_mean_accuracy:\n",
    "                            hyperparameters = {\n",
    "                                'layers': N_LAYERS,\n",
    "                                'nodes': N_NODES,\n",
    "                                'test_size': TEST_SIZE,\n",
    "                                'days_clipped': DAYS_TO_CLIP,\n",
    "                                'epochs': N_EPOCHS,\n",
    "                                'mean_accuracy': mean_accuracy\n",
    "                            }\n",
    "                            #best_layers = N_LAYERS\n",
    "                            #best_nodes = N_NODES\n",
    "                            #best_test_size = TEST_SIZE\n",
    "                            #best_days_clipped = DAYS_TO_CLIP\n",
    "                            #best_epochs = N_EPOCHS\n",
    "                            best_mean_accuracy = mean_accuracy\n",
    "                            best_model = model\n",
    "                        print(hyperparameters)\n",
    "                            \n",
    "    return model, hyperparameters\n",
    "\n",
    "model, params = run_cross_validation()\n",
    "\n",
    "                                                      \n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../data/raw/raw.csv', index_col=['Date'])\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz_df = raw_data[['Adj Close']]\n",
    "viz_df.columns = ['price']\n",
    "\n",
    "\n",
    "viz_df = pd.merge(viz_df, time_series_df, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "viz_df = viz_df.dropna()\n",
    "\n",
    "X_viz = viz_df[['back_5', 'back_4', 'back_3', 'back_2', 'back_1']].values\n",
    "\n",
    "preds_viz = model.predict(X_viz)\n",
    "preds_viz = np.exp(preds_viz)\n",
    "viz_df['predicted_price'] = preds_viz\n",
    "viz_df['predicted_price'] = viz_df['price'] * viz_df['predicted_price']\n",
    "viz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tomorrow():\n",
    "    X = tomorrows_predictors.values\n",
    "    prediction = model.predict(X)\n",
    "    prediction = np.exp(prediction)\n",
    "    adj_close = raw_data[['Adj Close']]\n",
    "    prices = adj_close.tail(1)\n",
    "    todays_price = float(prices.values[0])\n",
    "    tomorrows_price = float(todays_price) * float(prediction)\n",
    "    is_increase = bool(prediction>=1)\n",
    "    return todays_price, tomorrows_price, is_increase\n",
    "\n",
    "print(predict_tomorrow())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month = viz_df.loc['2018-05-01':'2018-06-30']\n",
    "month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This next plot will be very nice becuase it will show the model's ability to make predictions on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(15,15))\n",
    "_ = plt.plot(month['price'],  marker='.', alpha=0.9)\n",
    "_ = plt.plot(month['predicted_price'], marker='.', alpha=0.75)\n",
    "_ = plt.legend(['Actual Price', 'Predictions'])\n",
    "_ = plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.tail(40).head(30)\n",
    "X_test = test_df[['back_5', 'back_4', 'back_3', 'back_2', 'back_1']].values\n",
    "test_preds = model.predict(X_test)\n",
    "test_preds = np.exp(test_preds)\n",
    "test_df['price'] = raw_data['Adj Close']\n",
    "test_df['predictions'] = test_preds\n",
    "test_df['pred'] = (test_df['predictions'] * test_df['price'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(15,15))\n",
    "_ = plt.plot(test_df['price'], marker='.')\n",
    "_ = plt.plot(test_df['pred'], marker='.')\n",
    "_ = plt.xticks(rotation=90)\n",
    "_ = plt.legend(['Actual Price', 'Predictions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('stop notebook execution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_data(predictions):\n",
    "    \n",
    "    # undo scale\n",
    "    #scaler = joblib.load('../models/MinMaxScaler.save')\n",
    "    #unscaled_deltas = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    # undo log\n",
    "    #inv_log = np.exp(unscaled_deltas)\n",
    "    inv_log = np.exp(predictions)\n",
    "    \n",
    "    return inv_log\n",
    "x = revert_data(predictions)\n",
    "(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = joblib.load('../models/MinMaxScaler.save')\n",
    "unscaled_deltas = scaler.inverse_transform(predictions)\n",
    "unscaled_deltas\n",
    "\n",
    "scaler.inverse_transform([[0.81, 0.12, 3.3], [0,1, -2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[ 0.12417709, -0.08672323,  0.88525218],[-0.12340155,  0.1822511 , -0.73470684]])\n",
    "scaler.transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_log = np.exp(predictions)\n",
    "inv_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_log.min(), inv_log.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(14,7))\n",
    "_ = plt.plot(predictions, linestyle='None', marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dense_model(input_shape):\n",
    "    #initialize a sequential keras model\n",
    "    model = Sequential()\n",
    "\n",
    "    # build three layers with 100 nodes each\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "\n",
    "    # build final layer that will contain the output prediction\n",
    "    model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LSTR_model(input_shape):\n",
    "    # Matt and Druv's architecture\n",
    "    #initialize a sequential keras model\n",
    "    model = Sequential()\n",
    "\n",
    "    # build three layers with 100 nodes each\n",
    "    model.add(LSTR(50, return_sequence=True, input_shape=input_shape))\n",
    "    model.add(LSTR(50, return_sequence=True)\n",
    "    model.add(LSTR(50))\n",
    "\n",
    "    # build final layer that will contain the output prediction\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    mode.complile(loss='mse', optimizer='adam')\n",
    "    \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_to_test = [0.00001, 0.01, 1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    model = get_new_model(input_shape)\n",
    "    \n",
    "    # use Stochastic Gradient Descent\n",
    "    optimizer = SGD(lr=lr)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    mse = sum((predictions - y_test)**2)\n",
    "    \n",
    "    print(lr, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
