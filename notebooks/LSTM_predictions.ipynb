{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    Read csv data from the specified file location.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file, index_col='Date')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_recent_days(df, n_days):\n",
    "    \"\"\"\n",
    "    optional\n",
    "    remove recent days from data frame\n",
    "    \"\"\"\n",
    "    return(df[:-n_days])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predictors_and_targets(df):\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    predictors = df[['back_5', 'back_4', 'back_3', 'back_2', 'back_1']].values\n",
    "    assert type(predictors) is np.ndarray\n",
    "    \n",
    "    n_cols = predictors.shape[1]\n",
    "    \n",
    "    targets = df[['Adj Close']].values\n",
    "    assert type(targets) is np.ndarray\n",
    "    \n",
    "    return predictors, targets, n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE DATA CONSTANTS\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify location of time series data\n",
    "file_path = '../data/interim/time_series.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>back_5</th>\n",
       "      <th>back_4</th>\n",
       "      <th>back_3</th>\n",
       "      <th>back_2</th>\n",
       "      <th>back_1</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.002435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>-0.022141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>-0.022141</td>\n",
       "      <td>-0.002490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>-0.022141</td>\n",
       "      <td>-0.002490</td>\n",
       "      <td>-0.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>-0.011656</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>-0.029898</td>\n",
       "      <td>0.031629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>0.012455</td>\n",
       "      <td>-0.011656</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>-0.029898</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.018848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>-0.011656</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>-0.029898</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>0.061366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>0.073689</td>\n",
       "      <td>-0.029898</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>-0.016556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>-0.029898</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>-0.016556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14669 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              back_5    back_4    back_3    back_2    back_1  Adj Close\n",
       "Date                                                                   \n",
       "1962-01-02       NaN       NaN       NaN       NaN       NaN   0.014743\n",
       "1962-01-03       NaN       NaN       NaN       NaN  0.014743   0.002435\n",
       "1962-01-04       NaN       NaN       NaN  0.014743  0.002435  -0.022141\n",
       "1962-01-05       NaN       NaN  0.014743  0.002435 -0.022141  -0.002490\n",
       "1962-01-08       NaN  0.014743  0.002435 -0.022141 -0.002490  -0.002498\n",
       "...              ...       ...       ...       ...       ...        ...\n",
       "2020-04-03  0.014775  0.012455 -0.011656  0.073689 -0.029898   0.031629\n",
       "2020-04-06  0.012455 -0.011656  0.073689 -0.029898  0.031629   0.018848\n",
       "2020-04-07 -0.011656  0.073689 -0.029898  0.031629  0.018848   0.061366\n",
       "2020-04-08  0.073689 -0.029898  0.031629  0.018848  0.061366  -0.016556\n",
       "2020-04-09 -0.029898  0.031629  0.018848  0.061366 -0.016556        NaN\n",
       "\n",
       "[14669 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time series data\n",
    "time_series_df = read_data(file_path)\n",
    "time_series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14669 entries, 1962-01-02 to 2020-04-09\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   back_5     14664 non-null  float64\n",
      " 1   back_4     14665 non-null  float64\n",
      " 2   back_3     14666 non-null  float64\n",
      " 3   back_2     14667 non-null  float64\n",
      " 4   back_1     14668 non-null  float64\n",
      " 5   Adj Close  14668 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 802.2+ KB\n"
     ]
    }
   ],
   "source": [
    "time_series_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to format predictors and targets\n",
    "predictors, targets, n_cols = format_predictors_and_targets(time_series_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to range [0,1]\n",
    "X_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "predictors = X_scaler.fit_transform(predictors)\n",
    "targets = y_scaler.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for correct scaling\n",
    "assert min(predictors.flatten()) == 0\n",
    "assert max(predictors.flatten()) == 1\n",
    "assert min(targets.flatten()) == 0\n",
    "assert max(targets.flatten()) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important for Time Series Analysis:**\n",
    "\n",
    "The training set must only contain stock price data for dates prior to all of the test data.\n",
    "\n",
    "The model will be overly optimistic if it trained on future data and evaluated on previous data.\n",
    "\n",
    "\n",
    "RESULT: Random split will not work\n",
    "split needs to be sequential.\n",
    "\n",
    "\n",
    "[____________ALL_____SEQUENTIAL_______DATA______]\n",
    "\n",
    "\n",
    "[____________TRAINING    DATA_____],[___________TEST_DATA____]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and testing set\n",
    "# SHUFFLE = FALSE\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=TEST_SIZE, shuffle=False, stratify=None, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for sequential split\n",
    "assert np.argwhere(predictors == X_train[-1])[0][0] == (np.argwhere(predictors == X_test[0])[0][0]) -1\n",
    "assert np.argwhere(predictors == y_train[-1])[0][0] == (np.argwhere(predictors == y_test[0])[0][0]) -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12463, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12463, 1, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np.reshape(y_train, (y_train.shape[0], 1, y_train.shape[1]))\n",
    "#y_test = np.reshape(y_test, (y_test.shape[0], 1, y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential_LSTM(n_nodes, n_layers, add_dense):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(n_nodes, return_sequences=True, input_shape=X_train.shape[1:]))\n",
    "    \n",
    "\n",
    "    # add LSTM layers that also use nodes from the same layer\n",
    "    for i in range(n_layers-2):\n",
    "        model.add(LSTM(n_nodes, return_sequences=True))\n",
    "    \n",
    "    #return_sequences = False if next layer is not LSTM\n",
    "    model.add(LSTM(n_nodes, return_sequences=False))\n",
    "    \n",
    "    \n",
    "    if add_dense:\n",
    "        # add Fully Connected Layer\n",
    "        model.add(Dense(n_nodes, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL CONSTANTS\n",
    "N_NODES = 50\n",
    "N_LAYERS = 5\n",
    "ADD_DENSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 50)             11200     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1, 50)             20200     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1, 50)             20200     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 50)             20200     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 1, 50)             20200     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 114,801\n",
      "Trainable params: 114,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build Sequential Model\n",
    "model = build_sequential_LSTM(N_NODES, N_LAYERS, ADD_DENSE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE TRAINING CONSTANTS\n",
    "EPOCHS = 2 #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12463/12463 [==============================] - 6s 512us/step - loss: 0.0211\n",
      "Epoch 2/2\n",
      "12463/12463 [==============================] - 3s 247us/step - loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x781cdeebf150>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
