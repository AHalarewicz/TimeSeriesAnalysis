{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('../models/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify location of time series data\n",
    "file_path = '../data/interim/time_series.csv'\n",
    "N_LAYERS = 25\n",
    "N_NODES = 50\n",
    "TEST_SIZE = 0.25\n",
    "EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    \"\"\"\n",
    "    Read csv data from the specified file location.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file, index_col='Date')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_predictors_and_targets(df):\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    predictors = df[['back_5', 'back_4', 'back_3', 'back_2', 'back_1']].values\n",
    "    assert type(predictors) is np.ndarray\n",
    "    \n",
    "    n_cols = predictors.shape[1]\n",
    "    \n",
    "    targets = df[['Adj Close']].values\n",
    "    assert type(targets) is np.ndarray\n",
    "    \n",
    "    return predictors, targets, n_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequential(n_nodes, n_layers, n_cols):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(n_nodes, activation='relu', input_shape=(n_cols,)))\n",
    "    \n",
    "    for i in range(n_layers-1):\n",
    "        model.add(Dense(n_nodes, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_exp(predictions, y_test):\n",
    "    predictions = np.exp(predictions)\n",
    "    y_test_exp = np.exp(y_test)\n",
    "    return predictions, y_test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y, pred):\n",
    "    \n",
    "    #scale and shift binary results\n",
    "    # -1 -> stock went down\n",
    "    # +1 -> stock increased or stayed the same\n",
    "    y = ((y>=1)*2)-1\n",
    "    pred = ((pred>=1)*2)-1\n",
    "    \n",
    "    # stocks move in the same direction when a_i*b_i is positive\n",
    "    accuracy = (np.sum((y*pred)>=0)/len(y))*100\n",
    "    \n",
    "    print(\"Predicting change in stock price with %f%s accuracy\" % (accuracy,'%'))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples(num_samples=100):\n",
    "    time_series_df = read_data(file_path)\n",
    "    \n",
    "    predictors, targets, n_cols = format_predictors_and_targets(time_series_df)\n",
    "    \n",
    "    X_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    y_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    predictors = X_scaler.fit_transform(predictors)\n",
    "    targets = y_scaler.fit_transform(targets)\n",
    "    \n",
    "    model = build_sequential(N_NODES, N_LAYERS, n_cols)\n",
    "    \n",
    "    samples = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=TEST_SIZE)\n",
    "\n",
    "        model.fit(X_train, y_train, use_multiprocessing=True, epochs=EPOCHS)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        predictions = y_scaler.inverse_transform(predictions)\n",
    "        y_test = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "        predictions, y_test_exp = revert_exp(predictions, y_test)\n",
    "\n",
    "        accuracy = get_accuracy(y_test_exp, predictions)\n",
    "        \n",
    "        samples.append(accuracy)\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 3s 242us/step - loss: 0.0165\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 160us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 155us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 154us/step - loss: 0.0012\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 150us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 156us/step - loss: 0.0012\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 157us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 152us/step - loss: 0.0012\n",
      "Predicting change in stock price with 46.275580% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 155us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 157us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 158us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 154us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 156us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 157us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 159us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 159us/step - loss: 0.0011\n",
      "Predicting change in stock price with 46.548431% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 158us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 157us/step - loss: 0.0012\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 173us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 169us/step - loss: 0.0012\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 158us/step - loss: 0.0012\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 158us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 159us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 157us/step - loss: 0.0011\n",
      "Predicting change in stock price with 45.648022% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 185us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 204us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 194us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 183us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 171us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 169us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 171us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 179us/step - loss: 0.0011\n",
      "Predicting change in stock price with 47.094134% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 161us/step - loss: 0.0012\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 164us/step - loss: 0.0012\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 175us/step - loss: 0.0012\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 169us/step - loss: 0.0012\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 164us/step - loss: 0.0012\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 164us/step - loss: 0.0012\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 180us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 162us/step - loss: 0.0012\n",
      "Predicting change in stock price with 54.679400% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 159us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 160us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 164us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 180us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 178us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 226us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 177us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 185us/step - loss: 0.0011\n",
      "Predicting change in stock price with 55.416098% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 3s 241us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 223us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 214us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 214us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 206us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 3s 263us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 195us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 190us/step - loss: 0.0011\n",
      "Predicting change in stock price with 54.624829% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 182us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 181us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 177us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 181us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 176us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 200us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 188us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 182us/step - loss: 0.0011\n",
      "Predicting change in stock price with 54.461119% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 200us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 3s 244us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 187us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 227us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 207us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 221us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 182us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 178us/step - loss: 0.0011\n",
      "Predicting change in stock price with 54.570259% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 198us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 196us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 179us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 173us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 181us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 173us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 198us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 194us/step - loss: 0.0011\n",
      "Predicting change in stock price with 45.484311% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 176us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 179us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 186us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 190us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 187us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 173us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 176us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 173us/step - loss: 0.0011\n",
      "Predicting change in stock price with 55.061392% accuracy\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10994/10994 [==============================] - 2s 165us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 159us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 164us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 162us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 166us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 162us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 160us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 163us/step - loss: 0.0011\n",
      "Predicting change in stock price with 44.338336% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 160us/step - loss: 0.0010\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 162us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 161us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 183us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 175us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 166us/step - loss: 0.0010\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 190us/step - loss: 0.0010\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 177us/step - loss: 0.0011\n",
      "Predicting change in stock price with 55.252387% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 167us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 165us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 184us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 202us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 204us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 3s 230us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 3s 232us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 207us/step - loss: 0.0011\n",
      "Predicting change in stock price with 54.761255% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 167us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 171us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 175us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 173us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 178us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 186us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 187us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 205us/step - loss: 0.0011\n",
      "Predicting change in stock price with 54.433834% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 203us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 196us/step - loss: 0.0010\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 205us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 182us/step - loss: 0.0010\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 171us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 171us/step - loss: 0.0010\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 175us/step - loss: 0.0010\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 172us/step - loss: 0.0010\n",
      "Predicting change in stock price with 54.897681% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 184us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 198us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 190us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 174us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 174us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 174us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 172us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 181us/step - loss: 0.0011\n",
      "Predicting change in stock price with 55.279673% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 200us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 180us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 183us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 180us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 185us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 174us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 172us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 185us/step - loss: 0.0011\n",
      "Predicting change in stock price with 44.529332% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 188us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 211us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 208us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 207us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 202us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 204us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 212us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 212us/step - loss: 0.0011\n",
      "Predicting change in stock price with 55.388813% accuracy\n",
      "Epoch 1/8\n",
      "10994/10994 [==============================] - 2s 181us/step - loss: 0.0011\n",
      "Epoch 2/8\n",
      "10994/10994 [==============================] - 2s 208us/step - loss: 0.0011\n",
      "Epoch 3/8\n",
      "10994/10994 [==============================] - 2s 225us/step - loss: 0.0011\n",
      "Epoch 4/8\n",
      "10994/10994 [==============================] - 2s 209us/step - loss: 0.0011\n",
      "Epoch 5/8\n",
      "10994/10994 [==============================] - 2s 214us/step - loss: 0.0011\n",
      "Epoch 6/8\n",
      "10994/10994 [==============================] - 2s 198us/step - loss: 0.0011\n",
      "Epoch 7/8\n",
      "10994/10994 [==============================] - 2s 205us/step - loss: 0.0011\n",
      "Epoch 8/8\n",
      "10994/10994 [==============================] - 2s 194us/step - loss: 0.0011\n",
      "Predicting change in stock price with 45.511596% accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[46.27557980900409,\n",
       " 46.54843110504775,\n",
       " 45.64802182810369,\n",
       " 47.09413369713506,\n",
       " 54.679399727148706,\n",
       " 55.41609822646657,\n",
       " 54.624829467939975,\n",
       " 54.46111869031378,\n",
       " 54.570259208731244,\n",
       " 45.48431105047749,\n",
       " 55.06139154160983,\n",
       " 44.33833560709413,\n",
       " 55.25238744884038,\n",
       " 54.7612551159618,\n",
       " 54.43383356070941,\n",
       " 54.89768076398362,\n",
       " 55.279672578444746,\n",
       " 44.529331514324696,\n",
       " 55.38881309686221,\n",
       " 45.51159618008185]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_samples = collect_samples(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_samples = [46.27557980900409,\n",
    " 46.54843110504775,\n",
    " 45.64802182810369,\n",
    " 47.09413369713506,\n",
    " 54.679399727148706,\n",
    " 55.41609822646657,\n",
    " 54.624829467939975,\n",
    " 54.46111869031378,\n",
    " 54.570259208731244,\n",
    " 45.48431105047749,\n",
    " 55.06139154160983,\n",
    " 44.33833560709413,\n",
    " 55.25238744884038,\n",
    " 54.7612551159618,\n",
    " 54.43383356070941,\n",
    " 54.89768076398362,\n",
    " 55.279672578444746,\n",
    " 44.529331514324696,\n",
    " 55.38881309686221,\n",
    " 45.51159618008185]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_p(arr, p):\n",
    "    \"\"\"return a tuple of the lower and upper bounds of a p_% confindence interval\"\"\"\n",
    "    ends = 100 - p\n",
    "    left = ends/2\n",
    "    right = 100 - left\n",
    "    return np.percentile(arr, [left, right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_replicate_1d(data, func):\n",
    "    \"\"\"Draw a single bootstrap replicate\"\"\"\n",
    "    return func(np.random.choice(data, size=len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bs_reps(data, func, size=1):\n",
    "    \"\"\"Draw many bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "\n",
    "    return bs_replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_mean(samples):\n",
    "    \n",
    "    \"\"\" given a sample, use Bootstrap Statistics to return the distribution and the 95 % confidence interval for the mean as a tuple\"\"\"\n",
    "    # compute observed mean of sample\n",
    "    observed_mean = np.mean(samples)\n",
    "    \n",
    "    # generate 10,000 bootstrap replicates\n",
    "    N_reps = 10000\n",
    "    bs_replicates = draw_bs_reps(samples, np.mean, N_reps)\n",
    "    \n",
    "    # compute standard error of the mean \n",
    "    sem = np.std(samples) / np.sqrt(len(samples))\n",
    "    \n",
    "    # compute extremes of 95 percentile\n",
    "    int_min, int_max = percentile_p(bs_replicates, 95)\n",
    "    \n",
    "    conf_min, conf_max = percentile_p(bs_replicates, 95)\n",
    "    conf_range = bs_replicates[(bs_replicates >= conf_min) & (bs_replicates <= conf_max)]\n",
    "    \n",
    "    \n",
    "    # plot distribution of bootstrap replicates\n",
    "    _ , bins, _ = plt.hist(bs_replicates, bins=50, density=True, alpha=0.5)\n",
    "    _ = plt.hist(conf_range, bins=bins, density=True, alpha=1, color='b')\n",
    "    _ = plt.xlabel('mean')\n",
    "    _ = plt.ylabel('PDF')\n",
    "\n",
    "\n",
    "    _ = plt.axvline(conf_min, color='w', linestyle='-', linewidth=2.5)\n",
    "    _ = plt.axvline(conf_max, color='w', linestyle='-', linewidth=2.5)\n",
    "    _ = plt.axvline(np.mean(bs_replicates), color='w', linestyle=':')\n",
    "    _ = plt.axvline(observed_mean, color='r', alpha=0.5, linestyle=':')\n",
    "\n",
    "    _ = plt.title('95% Confidence Interval of the Mean')\n",
    "    print(np.mean(bs_replicates).round(3), observed_mean.round(3))\n",
    "    plt.show()\n",
    "    \n",
    "    return (bs_replicates, int_min, int_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.238 51.213\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bootstrapping = bootstrap_mean(accuracy_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.237540927694404"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicates, int_min, int_max = bootstrapping\n",
    "np.mean(replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
